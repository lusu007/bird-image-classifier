{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bird Species Image Recognition\n",
        "We are building a ML model using Tensorflow to recognise different bird species. This project is based on a [dataset](https://www.kaggle.com/gpiosenka/100-bird-species) from Kaggle.\n",
        "\n",
        "The vision behind this project is to provide an excellent model for a bird tracking and counting app. This App could take advantage of bird enthusiast taken pictures. The taken pictures are classified by our model and a heatmap of different bird species could be created.\n",
        "\n",
        "This notebook can take advantage of GPU Acceleration. Fortunatly Datalore provides a GPU instance with a Nvidia T4 GPU in it. This instance should be used for analysis, training and saving of the model. \n",
        "Further calculations and predictions using the trained model should use a smaller and slower instance to safe on computing time on the GPU instance.\n",
        "\n",
        "The exported model is saved under \"Attached Files\". You can access them via the menu on the left side or via the console windows under tools.\n",
        "In console you have to run the following command to get into the export directory `cd /data/notebook_files/export`.\n",
        "\n",
        "To download the trained model just switch to \"Attached Files\" and download the provided ZIP file in the `export` directory. (ZIP not provided yet)\n",
        "\n",
        "## Manual package installation\n",
        "To use the save and export block without any errors you have to install some Python package manually. In Datalore you can use the package installer on the left site menu.\n",
        "\n",
        "Packages:\n",
        "- zipdir"
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating, training and saving the model"
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import needed libraries\n",
        "All libraries used in the first section of the notebook are imported here to unclutter following code blocks. \n",
        "\n",
        "**Therefore this block must be executed to gurantee flawless execution of the following code blocks.**"
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Used for generating plots\n",
        "import matplotlib.pyplot as plt\n",
        "# Small math utility package\n",
        "import numpy as np\n",
        "# Tensorflow (library for ML)\n",
        "import tensorflow as tf\n",
        "# Small path and file interaction util package\n",
        "import pathlib\n",
        "# OS for file walking\n",
        "import os\n",
        "\n",
        "# Keras provides an easy to use interface for Tensorflow and is specifically made for neural networks\n",
        "from tensorflow import keras\n",
        "# A layer is the basic building block of a neural network in Keras\n",
        "from tensorflow.keras import layers\n",
        "# Sequential groups multiple layers into a Keras model\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and prepare data archive\n",
        "Before any computation can begin we have to download the choosen [dataset](https://www.kaggle.com/gpiosenka/100-bird-species) from Kaggle. The dataset is provided as a ZIP archive. To make use of the images contained inside the dataset we need to extract the ZIP archive.\n",
        "\n",
        "For further use the path to the training and validation dataset is saved into a variable.\n",
        "\n",
        "**If you use the original Kaggle link it is possible that the link expires after some time because it has an expire parameter in the URL**"
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://onedrive.live.com/download?cid=1D4188EA3D5DB234&resid=1D4188EA3D5DB234%2147165&authkey=AAyMv-YcCTKAAXw\"\n",
        "tf.keras.utils.get_file('archive', origin=dataset_url, extract=True)\n",
        "\n",
        "# paths to datasets in variables for further use\n",
        "training_ds_dir = pathlib.Path('/home/datalore/.keras/datasets/train')\n",
        "validation_ds_dir = pathlib.Path('/home/datalore/.keras/datasets/valid')\n",
        "test_ds_dir = pathlib.Path('/home/datalore/.keras/datasets/test')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can get some basic informations of the dataset."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('=== Training dataset ===')\n",
        "print('Category count (species):', len([element for element in training_ds_dir.iterdir() if element.is_dir()]))\n",
        "print('Image count (images overall):', len(list(training_ds_dir.glob('**/*.jpg'))))\n",
        "\n",
        "print('\\n=== Validation dataset ===')\n",
        "print('Category count (species):', len([element for element in validation_ds_dir.iterdir() if element.is_dir()]))\n",
        "print('Image count (images overall):', len(list(validation_ds_dir.glob('**/*.jpg'))))\n",
        "\n",
        "print('\\n=== Test dataset ===')\n",
        "print('Category count (species):', len([element for element in test_ds_dir.iterdir() if element.is_dir()]))\n",
        "print('Image count (images overall):', len(list(test_ds_dir.glob('**/*.jpg'))))"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load images into keras\n",
        "The interface library Keras provides an easy way to load images into a TensorFlow dataset. We can do that using Keras preprocessing.\n",
        "We are creating two datasets. The first one contains all classified training images and the other contains validation images for each class.\n",
        "\n",
        "To safe memory Keras can load the images in batches into a dataset. How many images are loaded at the same can be defined using a variable.\n",
        "\n",
        "For later use a variable containing all classnames gets created."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of a batch the images get loaded in\n",
        "batch_size = 32\n",
        "# Image height\n",
        "height = 224\n",
        "# Image width\n",
        "width = 224\n",
        "\n",
        "# Load training images into the training dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    training_ds_dir,\n",
        "    seed=123,                                                           \n",
        "    image_size=(height, width),\n",
        "    batch_size=batch_size)\n",
        "# Load validation images into the validation dataset\n",
        "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    validation_ds_dir,\n",
        "    seed=123,\n",
        "    image_size=(height, width),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# Array containing all classes\n",
        "class_names = train_ds.class_names\n",
        "print('\\nClasses:', class_names)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize data\n",
        "To give a small inspection in the dataset nine images are random selected and printed into the notebook."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "Data Augementation is used to mitigate overfitting. With Data Augmentation images are slightly modified to get more training images."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_augmented = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(height, width, 3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display nine augmented images to show how augmentation works."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = train_ds_augmented(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model\n",
        "A keras model consits of multiple layers. The Sequential object combines theses layers to a model.\n",
        "\n",
        "### [Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
        "* Extract features by applying filter (kernel) windows\n",
        "* applied activation function: \"rectified linear unit\" (relu)\n",
        "\n",
        "### [MaxPooling2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/)\n",
        "* reduces the Input along spatial dimensions by moving a 2x2 window over the image\n",
        "* takes the highest of the four values in window\n",
        "\n",
        "### [Dropout](https://keras.io/api/layers/regularization_layers/dropout/)\n",
        "* used to prevent overfitting\n",
        "* ignore randomly selected hidden layer neurons during training\n",
        "* reduces co-dependency of neurons\n",
        "\n",
        "### [Flatten](https://keras.io/api/layers/reshaping_layers/flatten/)\n",
        "* converts (\"flattens\") the data from two dimensions to one\n",
        "\n",
        "### [Dense](https://keras.io/api/layers/core_layers/dense/)\n",
        "* \"deeply connected layer\"\n",
        "* performs the actual classification"
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 275\n",
        "\n",
        "model = Sequential([\n",
        "  train_ds_augmented,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(512, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model\n",
        "With compiling the model we are configuring it for training."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model summary\n",
        "Print all information of the model."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "We define the amount of epochs and then train the model. A high amount of epochs increases the computation time but also increases the accuracy of the model until we are running into overfitting."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize training results\n",
        "To visualize our training results we are generating two plots. One containing the training accuracy and one for our loss values.\n",
        "With this chart we can optimise the model."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save accuracy values\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Save loss values\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "# Init figure for both plots\n",
        "plt.figure(figsize=(15, 10), dpi=100)\n",
        "\n",
        "# Subplot for accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# Subplot for loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Show both plots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete existing export\n",
        "Delete the existing exported data to ensure that no data of the old model is mixed with the new one."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete existing exported data\n",
        "import shutil\n",
        "shutil.rmtree('/data/notebook_files/export')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export and zip model\n",
        "Export the keras model into the export directory and zip it to simply downloading."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Export keras model\n",
        "pathlib.Path('/data/notebook_files/export/model').mkdir(parents=True, exist_ok=True)\n",
        "model.save('/data/notebook_files/export/model')\n",
        "\n",
        "# ZIP model directory to simplify download\n",
        "import zipdir\n",
        "zipdir.zipDirectory('/data/notebook_files/export/model', outputFile='/data/notebook_files/export/model.zip')\n",
        "\n",
        "import pickle\n",
        "with open('/data/notebook_files/export/history/history', 'wb') as file_pi:\n",
        "    pickle.dump(history, file_pi)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict on test dataset\n",
        "**Starting with this block all following blocks should be executed on a smaller instance to save GPU computation time. The model can be loaded from disk.**\n",
        "\n",
        "Load the exported model from disk into a keras model. After loading the model's summary is printed."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from file to save computation time\n",
        "model = keras.models.load_model('/data/notebook_files/export/model')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict a single image\n",
        "Use the model to predict a single manually picked images."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Init probably missing variables.\n",
        "# The variables could be missing if we dont execute all steps above and start with loading the model from the disk.\n",
        "height = 224\n",
        "width = 224\n",
        "\n",
        "# Load image with keras and expand it into a image batch\n",
        "african_crowned_crane_path = pathlib.Path('/home/datalore/.keras/datasets/test/AFRICAN CROWNED CRANE/2.jpg')\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    african_crowned_crane_path, target_size=(height, width)\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "# Predict the image\n",
        "predictions = model.predict(img_array)\n",
        "# Get confidence\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "# Print confidence and predicted species\n",
        "print(\n",
        "      'This bird is most likely a {} with a {:.2f} percent confidence.'\n",
        "      .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict all test images and analyze the accuracy\n",
        "Now we can predict all images in the provided test dataset. The following code cell predicts all images and add the result to a confidence array. With this confidence array we can generate the nice little plot below the nect but one code cell."
      ],
      "attachments": {},
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Init confidence array\n",
        "confidence = [0] * len(class_names)\n",
        "\n",
        "# Index must be -1 at start because os.walk starts with the root dir and not with the first subdir\n",
        "index = -1\n",
        "for directory, subdirectories, files in os.walk('/home/datalore/.keras/datasets/test/'):\n",
        "    for file in files:\n",
        "        # Load image with keras and expand it into a image batch\n",
        "        img = keras.preprocessing.image.load_img(\n",
        "            os.path.join(directory, file), target_size=(height, width)\n",
        "        )\n",
        "        img_array = keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = tf.expand_dims(img_array, 0)\n",
        "        # Predict the image\n",
        "        predictions = model.predict(img_array)\n",
        "        # Get confidence\n",
        "        score = tf.nn.softmax(predictions[0])\n",
        "        # Check if prediction is correct and add it to confidence array\n",
        "        confidence[index] += (class_names[np.argmax(score)] == pathlib.PurePath(directory).name and 1 or 0)\n",
        "    index += 1"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup plot that shows correctly predicted images as a bar chart\n",
        "fig, ax = plt.subplots(1, 1, figsize=(20, 100))\n",
        "y_pos = np.arange(len(class_names))\n",
        "ax.barh(y_pos, np.flip(confidence), align='center', height=.8)\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels(class_names)\n",
        "ax.invert_yaxis()\n",
        "ax.set_xlabel('Images correctly categorized')\n",
        "ax.set_title('How many images of each category are correctly predited?')\n",
        "plt.ylim(min(y_pos)-1, max(y_pos)+1)\n",
        "plt.savefig('/data/notebook_files/correctly_predicted.jpg')\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "history = pickle.load(open('/data/notebook_files/export/history/history', 'rb'))\n",
        "\n",
        "# Save accuracy values\n",
        "acc = history['accuracy']\n",
        "val_acc = history['val_accuracy']\n",
        "\n",
        "# Save loss values\n",
        "loss = history['loss']\n",
        "val_loss = history['val_loss']\n",
        "\n",
        "epochs_range = range(100)\n",
        "\n",
        "# Init figure for both plots\n",
        "plt.figure(figsize=(15, 10), dpi=100)\n",
        "\n",
        "# Subplot for accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# Subplot for loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Show both plots\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}